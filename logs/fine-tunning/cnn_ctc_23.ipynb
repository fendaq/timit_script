{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* batch normalization degrade performance when used with residual convnet\n",
    "* he_normal, he_uniform initializer slow down convergence\n",
    "\n",
    "** i misused dropout layer (training=False), so maybe above conditon not true. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phn_61 = ['aa', 'ae', 'ah', 'ao', 'aw', 'ax', 'ax-h', 'axr', 'ay', 'b', 'bcl', 'ch', 'd', 'dcl', 'dh', 'dx', 'eh', 'el', 'em', 'en', 'eng', 'epi', 'er', 'ey', 'f', 'g', 'gcl', 'h#', 'hh', 'hv', 'ih', 'ix', 'iy', 'jh', 'k', 'kcl', 'l', 'm', 'n', 'ng', 'nx', 'ow', 'oy', 'p', 'pau', 'pcl', 'q', 'r', 's', 'sh', 't', 'tcl', 'th', 'uh', 'uw', 'ux', 'v', 'w', 'y', 'z', 'zh']\n",
    "phn_39 = ['ae', 'ao', 'aw', 'ax', 'ay', 'b', 'ch', 'd', 'dh', 'dx', 'eh', 'er', 'ey', 'f', 'g', 'h#', 'hh', 'ix', 'iy', 'jh', 'k', 'l', 'm', 'n', 'ng', 'ow', 'oy', 'p', 'r', 's', 't', 'th', 'uh', 'uw', 'v', 'w', 'y', 'z', 'zh']\n",
    "mapping = {'ah': 'ax', 'ax-h': 'ax', 'ux': 'uw', 'aa': 'ao', 'ih': 'ix', 'axr': 'er', 'el': 'l', 'em': 'm', 'en': 'n', 'nx': 'n', 'eng': 'ng', 'sh': 'zh', 'hv': 'hh', 'bcl': 'h#', 'pcl': 'h#', 'dcl': 'h#', 'tcl': 'h#', 'gcl': 'h#', 'kcl': 'h#', 'q': 'h#', 'epi': 'h#', 'pau': 'h#'}\n",
    "\n",
    "TRAIN_FILE = './data/fbank/train.tfrecords'\n",
    "DEV_FILE = './data/fbank/dev.tfrecords'\n",
    "TEST_FILE = './data/fbank/test.tfrecords'\n",
    "checkpoints_path = './model/cnn+ctc/ckpt'\n",
    "ft_checkpoints_path = './model/cnn+ctc/finetunning/ckpt'\n",
    "\n",
    "feat_type = 'fbank'\n",
    "feats_dim = 39 if feat_type=='mfcc' else 123 # log filter bank + energy term\n",
    "\n",
    "batch_size = 20\n",
    "num_hidden = 128\n",
    "n_hidden_layer = 3\n",
    "learning_rate = 0.0001\n",
    "num_classes = len(phn_61)+1 # num of phoneme + blank\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, batch_size, num_hidden, n_hidden_layer, feats_dim, num_classes, learning_rate=0.001, optimizer=None,\n",
    "                 phn_61=None, phn_39=None, mapping=None, file_type=None, model_type=None):\n",
    "        \n",
    "        iterator = self._get_iterator(batch_size, feats_dim, file_type, model_type)\n",
    "        self.iterator_initializer = iterator.initializer\n",
    "        \n",
    "        batched_data = iterator.get_next()\n",
    "        features = batched_data[0]\n",
    "        labels = batched_data[1]\n",
    "        feats_seq_len = tf.to_int32(batched_data[2])\n",
    "        labels_sparse = self._get_sparse_tensor(labels, -1)\n",
    "        \n",
    "        logits = self._compute_logits(features, feats_seq_len, num_hidden, n_hidden_layer, num_classes)\n",
    "        self.saver = tf.train.Saver() # save graph until logits\n",
    "        \n",
    "        if model_type=='train':\n",
    "            self.loss = self._compute_loss(labels_sparse, feats_seq_len, logits)\n",
    "            self.update_step = self._get_update_step(self.loss, learning_rate, optimizer)\n",
    "        elif model_type=='eval':\n",
    "            self.loss = self._compute_loss(labels_sparse, feats_seq_len, logits)\n",
    "        else: # 'infer'\n",
    "            self.per = self._compute_per(labels_sparse, feats_seq_len, logits, phn_61, phn_39, mapping)\n",
    "        \n",
    "    def _get_sparse_tensor(self, dense, default):\n",
    "        indices = tf.to_int64(tf.where(tf.not_equal(dense, default)))\n",
    "        vals = tf.to_int32(tf.gather_nd(dense, indices))\n",
    "        shape = tf.to_int64(tf.shape(dense))\n",
    "        return tf.SparseTensor(indices, vals, shape)\n",
    "                \n",
    "    def _get_iterator(self, batch_size, feats_dim, file_type, model_type):\n",
    "        dataset = tf.contrib.data.TFRecordDataset(file_type)\n",
    "        context_features = {'feats_seq_len': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "                           'labels_seq_len': tf.FixedLenFeature([], dtype=tf.int64)}\n",
    "        sequence_features = {'features': tf.FixedLenSequenceFeature([feats_dim], dtype=tf.float32),\n",
    "                            'labels': tf.FixedLenSequenceFeature([], dtype=tf.int64)}\n",
    "        dataset = dataset.map(lambda serialized_example: tf.parse_single_sequence_example(serialized_example,\n",
    "                                                                        context_features=context_features,\n",
    "                                                                        sequence_features=sequence_features))\n",
    "        dataset = dataset.map(lambda context, sequence: (sequence['features'], sequence['labels'],\n",
    "                                                        context['feats_seq_len'], context['labels_seq_len']))\n",
    "        def batching_func(x):\n",
    "            return x.padded_batch(batch_size,\n",
    "                                 padded_shapes=(tf.TensorShape([None, feats_dim]),\n",
    "                                               tf.TensorShape([None]),\n",
    "                                               tf.TensorShape([]),\n",
    "                                               tf.TensorShape([])),\n",
    "                                 padding_values=(tf.cast(0, tf.float32),\n",
    "                                                tf.cast(-1, tf.int64),\n",
    "                                                tf.cast(0, tf.int64),\n",
    "                                                tf.cast(0, tf.int64)))\n",
    "        def key_func(features, labels, feats_seq_len, labels_seq_len):\n",
    "            f0 = lambda: tf.constant(0, tf.int64)\n",
    "            f1 = lambda: tf.constant(1, tf.int64)\n",
    "            f2 = lambda: tf.constant(2, tf.int64)\n",
    "            f3 = lambda: tf.constant(3, tf.int64)\n",
    "            f4 = lambda: tf.constant(4, tf.int64)\n",
    "            f5 = lambda: tf.constant(5, tf.int64)\n",
    "            f6 = lambda: tf.constant(6, tf.int64)\n",
    "            \n",
    "            return tf.case([(tf.less_equal(feats_seq_len, 200), f0),\n",
    "                   (tf.less_equal(feats_seq_len, 250), f1),\n",
    "                   (tf.less_equal(feats_seq_len, 300), f2),\n",
    "                   (tf.less_equal(feats_seq_len, 350), f3),\n",
    "                   (tf.less_equal(feats_seq_len, 400), f4),\n",
    "                   (tf.less_equal(feats_seq_len, 500), f5)], default=f6)\n",
    "        def reduce_func(bucket_id, windowed_data):\n",
    "            return batching_func(windowed_data)\n",
    "        \n",
    "        if model_type=='train':\n",
    "            dataset = dataset.shuffle(10000)\n",
    "            batched_dataset = dataset.group_by_window(key_func=key_func, reduce_func=reduce_func, window_size=batch_size)\n",
    "            batched_dataset = batched_dataset.shuffle(10000)\n",
    "        else:\n",
    "            batched_dataset = batching_func(dataset)\n",
    "            \n",
    "        return batched_dataset.make_initializable_iterator()\n",
    "    \n",
    "    def _compute_logits(self, features, feats_seq_len, num_hidden, n_hidden_layer, num_classes):\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        self.training = tf.placeholder(tf.bool)\n",
    "        \n",
    "        features = tf.stack(tf.split(features, num_or_size_splits=3, axis=-1), axis=0) # shape = [3, batch, max_time, feats_dim/3]\n",
    "        features = tf.transpose(features, [1,3,2,0]) # shape = [batch, feats_dim/3, max_time, channels]\n",
    "        \n",
    "        conv1 = tf.layers.conv2d(features, filters=128, kernel_size=(3,5), strides=(1,1), padding='same', activation=tf.nn.relu)\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, pool_size=(3,1), strides=(3,1), padding='same') # 41->14,  do not use SAME!!!!\n",
    "        conv1 = tf.layers.dropout(conv1, rate=1-self.keep_prob, training=self.training)\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(conv1, filters=128, kernel_size=(3,5), strides=(1,1), padding='same', activation=tf.nn.relu)\n",
    "        conv2 = tf.layers.dropout(conv2, rate=1-self.keep_prob, training=self.training)\n",
    "        \n",
    "        conv3 = tf.layers.conv2d(conv2, filters=128, kernel_size=(3,5), strides=(1,1), padding='same', activation=tf.nn.relu)\n",
    "        conv3 = tf.layers.dropout(conv3, rate=1-self.keep_prob, training=self.training)\n",
    "        \n",
    "        conv4 = tf.layers.conv2d(conv3, filters=128, kernel_size=(3,5), strides=(1,1), padding='same', activation=tf.nn.relu)\n",
    "        conv4 = tf.layers.dropout(conv4, rate=1-self.keep_prob, training=self.training)\n",
    "        \n",
    "        conv5 = tf.layers.conv2d(conv4, filters=128, kernel_size=(3,5), strides=(1,1), padding='same', activation=tf.nn.relu)\n",
    "        conv5 = tf.layers.dropout(conv5, rate=1-self.keep_prob, training=self.training)\n",
    "        \n",
    "        conv6 = tf.layers.conv2d(conv5, filters=128, kernel_size=(3,5), strides=(1,1), padding='same', activation=tf.nn.relu)\n",
    "        conv6 = tf.layers.dropout(conv6, rate=1-self.keep_prob, training=self.training)\n",
    "        \n",
    "        conv7 = tf.layers.conv2d(conv6, filters=128, kernel_size=(3,5), strides=(1,1), padding='same', activation=tf.nn.relu)\n",
    "        conv7 = tf.layers.dropout(conv7, rate=1-self.keep_prob, training=self.training)\n",
    "        \n",
    "        conv8 = tf.layers.conv2d(conv7, filters=128, kernel_size=(3,5), strides=(1,1), padding='same', activation=tf.nn.relu)\n",
    "        conv8 = tf.layers.dropout(conv8, rate=1-self.keep_prob, training=self.training)\n",
    "    \n",
    "        conv9 = tf.layers.conv2d(conv8, filters=128, kernel_size=(3,5), strides=(1,1), padding='same', activation=tf.nn.relu)\n",
    "        conv9 = tf.layers.dropout(conv9, rate=1-self.keep_prob, training=self.training)\n",
    "        \n",
    "        conv10 = tf.layers.conv2d(conv9, filters=128, kernel_size=(3,5), strides=(1,1), padding='same', activation=tf.nn.relu)\n",
    "        conv10 = tf.layers.dropout(conv10, rate=1-self.keep_prob, training=self.training)\n",
    "        \n",
    "        flattend = tf.transpose(conv10, [0,2,1,3]) # shape = [batch, width, height, channels] = [None, None, 14, 200]\n",
    "        flattend = tf.reshape(flattend, [tf.shape(flattend)[0], tf.shape(flattend)[1], 14*128]) # 41 / 3 -> 14\n",
    "        \n",
    "        fc1 = tf.layers.dense(flattend, 1024, activation=tf.nn.relu)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=1-self.keep_prob, training=self.training)\n",
    "        \n",
    "        fc2 = tf.layers.dense(fc1, 1024, activation=tf.nn.relu)\n",
    "        fc2 = tf.layers.dropout(fc2, rate=1-self.keep_prob, training=self.training)\n",
    "        \n",
    "        fc3 = tf.layers.dense(fc2, 1024, activation=tf.nn.relu)\n",
    "        fc3 = tf.layers.dropout(fc3, rate=1-self.keep_prob, training=self.training)\n",
    "        \n",
    "        return tf.layers.dense(fc3, num_classes)\n",
    "    \n",
    "    def _compute_loss(self, labels_sparse, feats_seq_len, logits):\n",
    "        return tf.reduce_mean(tf.nn.ctc_loss(labels=labels_sparse, inputs=logits, sequence_length=feats_seq_len, time_major=False))\n",
    "    \n",
    "    def _get_update_step(self, loss, learning_rate, optimizer):    \n",
    "        params = tf.trainable_variables()\n",
    "        gradients = tf.gradients(loss, params)\n",
    "        clipped_gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "        if optimizer=='adam':\n",
    "            opt = tf.train.AdamOptimizer(learning_rate)\n",
    "        elif optimizer=='sgd':\n",
    "            opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        elif optimizer=='momentum':\n",
    "            opt = tf.train.MomentumOptimizer(learning_rate, momentum=0.9, use_nesterov=True)\n",
    "        return opt.apply_gradients(zip(clipped_gradients, params))\n",
    "        \n",
    "    def _compute_per(self, labels_sparse, feats_seq_len, logits, phn_61, phn_39, mapping):\n",
    "        phn_61_tensor = tf.constant(phn_61, dtype=tf.string)\n",
    "        phn_39_tensor = tf.constant(phn_39, dtype=tf.string)\n",
    "        mapping_table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(list(mapping.keys()), list(mapping.values())), default_value='')\n",
    "        self.mapping_table_init = mapping_table.init\n",
    "        \n",
    "        logits = tf.transpose(logits, [1,0,2])\n",
    "        decoded, _ = tf.nn.ctc_greedy_decoder(logits, feats_seq_len)\n",
    "        decoded = tf.to_int32(decoded[0])\n",
    "        \n",
    "        def map_to_reduced_phn(p):\n",
    "            val = mapping_table.lookup(phn_61_tensor[p])\n",
    "            f1 = lambda: tf.to_int32(tf.reduce_min(tf.where(tf.equal(val, phn_39_tensor))))\n",
    "            f2 = lambda: tf.to_int32(tf.reduce_min(tf.where(tf.equal(phn_61_tensor[p], phn_39_tensor))))\n",
    "            return tf.cond(tf.not_equal(val, ''), f1, f2)\n",
    "\n",
    "        decoded_reduced = tf.SparseTensor(decoded.indices, tf.map_fn(map_to_reduced_phn, decoded.values), decoded.dense_shape)\n",
    "        labels_reduced = tf.SparseTensor(labels_sparse.indices, tf.map_fn(map_to_reduced_phn, labels_sparse.values), labels_sparse.dense_shape)\n",
    "        return tf.reduce_sum(tf.edit_distance(decoded_reduced, labels_reduced, normalize=False)) , tf.to_float(tf.size(labels_reduced.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:, \n",
      "train_loss=193.050, time = 84s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-1\n",
      "\tdev_loss=295.825, time=6s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-1\n",
      "\t\ttest_per=0.957, time=6s\n",
      "Epoch 2/100:, \n",
      "train_loss=148.971, time = 76s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-2\n",
      "\tdev_loss=231.586, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-2\n",
      "\t\ttest_per=0.952, time=5s\n",
      "Epoch 3/100:, \n",
      "train_loss=145.583, time = 76s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-3\n",
      "\tdev_loss=187.160, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-3\n",
      "\t\ttest_per=0.944, time=5s\n",
      "Epoch 4/100:, \n",
      "train_loss=141.447, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-4\n",
      "\tdev_loss=166.341, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-4\n",
      "\t\ttest_per=0.944, time=6s\n",
      "Epoch 5/100:, \n",
      "train_loss=116.955, time = 76s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-5\n",
      "\tdev_loss=133.687, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-5\n",
      "\t\ttest_per=0.665, time=7s\n",
      "Epoch 6/100:, \n",
      "train_loss=95.250, time = 76s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-6\n",
      "\tdev_loss=104.535, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-6\n",
      "\t\ttest_per=0.498, time=8s\n",
      "Epoch 7/100:, \n",
      "train_loss=82.886, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-7\n",
      "\tdev_loss=80.175, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-7\n",
      "\t\ttest_per=0.447, time=8s\n",
      "Epoch 8/100:, \n",
      "train_loss=75.369, time = 76s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-8\n",
      "\tdev_loss=77.383, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-8\n",
      "\t\ttest_per=0.428, time=9s\n",
      "Epoch 9/100:, \n",
      "train_loss=70.180, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-9\n",
      "\tdev_loss=69.427, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-9\n",
      "\t\ttest_per=0.399, time=9s\n",
      "Epoch 10/100:, \n",
      "train_loss=66.196, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-10\n",
      "\tdev_loss=59.833, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-10\n",
      "\t\ttest_per=0.359, time=9s\n",
      "Epoch 11/100:, \n",
      "train_loss=63.196, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-11\n",
      "\tdev_loss=60.012, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-11\n",
      "\t\ttest_per=0.351, time=9s\n",
      "Epoch 12/100:, \n",
      "train_loss=60.447, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-12\n",
      "\tdev_loss=53.302, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-12\n",
      "\t\ttest_per=0.343, time=9s\n",
      "Epoch 13/100:, \n",
      "train_loss=58.274, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-13\n",
      "\tdev_loss=53.461, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-13\n",
      "\t\ttest_per=0.331, time=9s\n",
      "Epoch 14/100:, \n",
      "train_loss=56.490, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-14\n",
      "\tdev_loss=48.991, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-14\n",
      "\t\ttest_per=0.314, time=9s\n",
      "Epoch 15/100:, \n",
      "train_loss=54.811, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-15\n",
      "\tdev_loss=47.036, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-15\n",
      "\t\ttest_per=0.312, time=9s\n",
      "Epoch 16/100:, \n",
      "train_loss=53.523, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-16\n",
      "\tdev_loss=47.869, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-16\n",
      "\t\ttest_per=0.306, time=9s\n",
      "Epoch 17/100:, \n",
      "train_loss=52.108, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-17\n",
      "\tdev_loss=47.097, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-17\n",
      "\t\ttest_per=0.308, time=9s\n",
      "Epoch 18/100:, \n",
      "train_loss=51.477, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-18\n",
      "\tdev_loss=47.262, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-18\n",
      "\t\ttest_per=0.303, time=9s\n",
      "Epoch 19/100:, \n",
      "train_loss=50.135, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-19\n",
      "\tdev_loss=44.914, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-19\n",
      "\t\ttest_per=0.298, time=9s\n",
      "Epoch 20/100:, \n",
      "train_loss=49.365, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-20\n",
      "\tdev_loss=43.499, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-20\n",
      "\t\ttest_per=0.295, time=9s\n",
      "Epoch 21/100:, \n",
      "train_loss=48.256, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-21\n",
      "\tdev_loss=42.154, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-21\n",
      "\t\ttest_per=0.287, time=9s\n",
      "Epoch 22/100:, \n",
      "train_loss=47.618, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-22\n",
      "\tdev_loss=41.285, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-22\n",
      "\t\ttest_per=0.281, time=9s\n",
      "Epoch 23/100:, \n",
      "train_loss=46.795, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-23\n",
      "\tdev_loss=42.053, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-23\n",
      "\t\ttest_per=0.279, time=9s\n",
      "Epoch 24/100:, \n",
      "train_loss=46.007, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-24\n",
      "\tdev_loss=40.595, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-24\n",
      "\t\ttest_per=0.274, time=9s\n",
      "Epoch 25/100:, \n",
      "train_loss=45.244, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-25\n",
      "\tdev_loss=39.319, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-25\n",
      "\t\ttest_per=0.267, time=9s\n",
      "Epoch 26/100:, \n",
      "train_loss=44.775, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-26\n",
      "\tdev_loss=38.681, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-26\n",
      "\t\ttest_per=0.264, time=9s\n",
      "Epoch 27/100:, \n",
      "train_loss=44.161, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-27\n",
      "\tdev_loss=39.607, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-27\n",
      "\t\ttest_per=0.261, time=9s\n",
      "Epoch 28/100:, \n",
      "train_loss=43.430, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-28\n",
      "\tdev_loss=38.642, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-28\n",
      "\t\ttest_per=0.261, time=9s\n",
      "Epoch 29/100:, \n",
      "train_loss=42.842, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-29\n",
      "\tdev_loss=39.174, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-29\n",
      "\t\ttest_per=0.264, time=9s\n",
      "Epoch 30/100:, \n",
      "train_loss=42.419, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-30\n",
      "\tdev_loss=38.286, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-30\n",
      "\t\ttest_per=0.264, time=9s\n",
      "Epoch 31/100:, \n",
      "train_loss=42.001, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-31\n",
      "\tdev_loss=37.195, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-31\n",
      "\t\ttest_per=0.259, time=9s\n",
      "Epoch 32/100:, \n",
      "train_loss=41.293, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-32\n",
      "\tdev_loss=37.155, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-32\n",
      "\t\ttest_per=0.260, time=9s\n",
      "Epoch 33/100:, \n",
      "train_loss=40.873, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-33\n",
      "\tdev_loss=37.508, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-33\n",
      "\t\ttest_per=0.258, time=9s\n",
      "Epoch 34/100:, \n",
      "train_loss=40.581, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-34\n",
      "\tdev_loss=37.048, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-34\n",
      "\t\ttest_per=0.257, time=9s\n",
      "Epoch 35/100:, \n",
      "train_loss=40.255, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-35\n",
      "\tdev_loss=37.573, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-35\n",
      "\t\ttest_per=0.256, time=9s\n",
      "Epoch 36/100:, \n",
      "train_loss=39.745, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-36\n",
      "\tdev_loss=35.641, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\ttest_per=0.252, time=9s\n",
      "Epoch 37/100:, \n",
      "train_loss=39.208, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-37\n",
      "\tdev_loss=35.881, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-37\n",
      "\t\ttest_per=0.249, time=9s\n",
      "Epoch 38/100:, \n",
      "train_loss=38.746, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-38\n",
      "\tdev_loss=36.512, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-38\n",
      "\t\ttest_per=0.248, time=9s\n",
      "Epoch 39/100:, \n",
      "train_loss=38.748, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-39\n",
      "\tdev_loss=36.940, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-39\n",
      "\t\ttest_per=0.248, time=9s\n",
      "Epoch 40/100:, \n",
      "train_loss=38.369, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-40\n",
      "\tdev_loss=35.844, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-40\n",
      "\t\ttest_per=0.250, time=9s\n",
      "Epoch 41/100:, \n",
      "train_loss=37.740, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-41\n",
      "\tdev_loss=34.224, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-41\n",
      "\t\ttest_per=0.244, time=9s\n",
      "Epoch 42/100:, \n",
      "train_loss=37.473, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-42\n",
      "\tdev_loss=35.047, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-42\n",
      "\t\ttest_per=0.246, time=9s\n",
      "Epoch 43/100:, \n",
      "train_loss=37.073, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-43\n",
      "\tdev_loss=33.754, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-43\n",
      "\t\ttest_per=0.238, time=9s\n",
      "Epoch 44/100:, \n",
      "train_loss=36.902, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-44\n",
      "\tdev_loss=34.255, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-44\n",
      "\t\ttest_per=0.239, time=9s\n",
      "Epoch 45/100:, \n",
      "train_loss=36.511, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-45\n",
      "\tdev_loss=34.410, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-45\n",
      "\t\ttest_per=0.241, time=9s\n",
      "Epoch 46/100:, \n",
      "train_loss=36.356, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-46\n",
      "\tdev_loss=34.677, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-46\n",
      "\t\ttest_per=0.242, time=9s\n",
      "Epoch 47/100:, \n",
      "train_loss=35.922, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-47\n",
      "\tdev_loss=34.907, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-47\n",
      "\t\ttest_per=0.238, time=9s\n",
      "Epoch 48/100:, \n",
      "train_loss=35.779, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-48\n",
      "\tdev_loss=33.378, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-48\n",
      "\t\ttest_per=0.236, time=9s\n",
      "Epoch 49/100:, \n",
      "train_loss=35.436, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-49\n",
      "\tdev_loss=33.428, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-49\n",
      "\t\ttest_per=0.241, time=9s\n",
      "Epoch 50/100:, \n",
      "train_loss=35.130, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-50\n",
      "\tdev_loss=33.607, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-50\n",
      "\t\ttest_per=0.237, time=9s\n",
      "Epoch 51/100:, \n",
      "train_loss=34.671, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-51\n",
      "\tdev_loss=32.948, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-51\n",
      "\t\ttest_per=0.233, time=9s\n",
      "Epoch 52/100:, \n",
      "train_loss=34.403, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-52\n",
      "\tdev_loss=32.853, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-52\n",
      "\t\ttest_per=0.234, time=9s\n",
      "Epoch 53/100:, \n",
      "train_loss=34.164, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-53\n",
      "\tdev_loss=32.863, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-53\n",
      "\t\ttest_per=0.231, time=9s\n",
      "Epoch 54/100:, \n",
      "train_loss=34.096, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-54\n",
      "\tdev_loss=32.687, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-54\n",
      "\t\ttest_per=0.238, time=9s\n",
      "Epoch 55/100:, \n",
      "train_loss=33.743, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-55\n",
      "\tdev_loss=33.230, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-55\n",
      "\t\ttest_per=0.233, time=9s\n",
      "Epoch 56/100:, \n",
      "train_loss=33.560, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-56\n",
      "\tdev_loss=33.198, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-56\n",
      "\t\ttest_per=0.233, time=9s\n",
      "Epoch 57/100:, \n",
      "train_loss=33.241, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-57\n",
      "\tdev_loss=34.186, time=4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-57\n",
      "\t\ttest_per=0.234, time=9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-099ceb271ae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             _, cost = train_sess.run([train_model.update_step, train_model.loss], feed_dict={train_model.keep_prob: 0.7,\n\u001b[1;32m---> 30\u001b[1;33m                                                                                              train_model.training: True})\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sappyprg\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sappyprg\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sappyprg\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sappyprg\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sappyprg\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_graph = tf.Graph()\n",
    "dev_graph = tf.Graph()\n",
    "test_graph = tf.Graph()\n",
    "\n",
    "with train_graph.as_default():\n",
    "    train_model = Model(batch_size, num_hidden, n_hidden_layer, feats_dim, num_classes, learning_rate=learning_rate, \n",
    "                 optimizer='adam', file_type=TRAIN_FILE, model_type='train')\n",
    "    initializer = tf.global_variables_initializer()\n",
    "\n",
    "with dev_graph.as_default():\n",
    "    dev_model = Model(batch_size, num_hidden, n_hidden_layer, feats_dim, num_classes, learning_rate=learning_rate, \n",
    "                 file_type=DEV_FILE, model_type='eval')\n",
    "with test_graph.as_default():\n",
    "    test_model = Model(batch_size, num_hidden, n_hidden_layer, feats_dim, num_classes, learning_rate=learning_rate, \n",
    "                 phn_61=phn_61, phn_39=phn_39, mapping=mapping, file_type=TEST_FILE, model_type='infer')\n",
    "    \n",
    "train_sess = tf.Session(graph=train_graph)\n",
    "train_sess.run(initializer)\n",
    "dev_sess = tf.Session(graph=dev_graph)\n",
    "test_sess = tf.Session(graph=test_graph)\n",
    "test_sess.run(test_model.mapping_table_init)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_sess.run(train_model.iterator_initializer)\n",
    "    train_loss = []\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            _, cost = train_sess.run([train_model.update_step, train_model.loss], feed_dict={train_model.keep_prob: 0.7,\n",
    "                                                                                             train_model.training: True})\n",
    "            train_loss.append(cost)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            end = time.time()\n",
    "            log = \"Epoch {}/{}:, \\ntrain_loss={:.3f}, time = {:.0f}s\"\n",
    "            print(log.format(epoch+1, epochs, np.mean(train_loss), end-start))\n",
    "            checkpoint_path = train_model.saver.save(train_sess, checkpoints_path, global_step=epoch+1)\n",
    "            \n",
    "            dev_model.saver.restore(dev_sess, checkpoint_path)\n",
    "            dev_sess.run(dev_model.iterator_initializer)\n",
    "            dev_loss = []\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                try:\n",
    "                    cost = dev_sess.run(dev_model.loss, feed_dict={dev_model.keep_prob: 1.0, dev_model.training: False})\n",
    "                    dev_loss.append(cost)\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    end = time.time()\n",
    "                    log = \"\\tdev_loss={:.3f}, time={:.0f}s\"\n",
    "                    print(log.format(np.mean(dev_loss), end-start))\n",
    "                    break\n",
    "            \n",
    "            test_model.saver.restore(test_sess, checkpoint_path)\n",
    "            test_sess.run(test_model.iterator_initializer)\n",
    "            test_per = []\n",
    "            test_seq_len = []\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                try:\n",
    "                    _per, seq_len = test_sess.run(test_model.per, feed_dict={test_model.keep_prob: 1.0, test_model.training: False})\n",
    "                    test_per.append(_per)\n",
    "                    test_seq_len.append(seq_len)\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    end = time.time()\n",
    "                    log = '\\t\\ttest_per={:.3f}, time={:.0f}s'\n",
    "                    print(log.format(sum(test_per)/sum(test_seq_len), end-start))\n",
    "                    break\n",
    "            \n",
    "            break\n",
    "            \n",
    "train_sess.close()\n",
    "dev_sess.close()\n",
    "test_sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restored_ckpt_path = './model/cnn+ctc/ckpt-54'\n",
    "ft_learning_rate = 1e-3\n",
    "ft_batch_size = 20\n",
    "ft_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/ckpt-54\n",
      "Epoch 1/100:, \n",
      "train_loss=33.535, time = 74s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/finetunning/ckpt-1\n",
      "\tdev_loss=32.248, time = 4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/finetunning/ckpt-1\n",
      "\t\ttest_per=0.232, time=9s\n",
      "Epoch 2/100:, \n",
      "train_loss=33.009, time = 75s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/finetunning/ckpt-2\n",
      "\tdev_loss=32.379, time = 4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/finetunning/ckpt-2\n",
      "\t\ttest_per=0.231, time=9s\n",
      "Epoch 3/100:, \n",
      "train_loss=32.928, time = 77s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/finetunning/ckpt-3\n",
      "\tdev_loss=32.152, time = 4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/finetunning/ckpt-3\n",
      "\t\ttest_per=0.231, time=9s\n",
      "Epoch 4/100:, \n",
      "train_loss=32.834, time = 83s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/finetunning/ckpt-4\n",
      "\tdev_loss=32.355, time = 4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/finetunning/ckpt-4\n",
      "\t\ttest_per=0.233, time=9s\n",
      "Epoch 5/100:, \n",
      "train_loss=32.893, time = 83s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/finetunning/ckpt-5\n",
      "\tdev_loss=32.628, time = 4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/finetunning/ckpt-5\n",
      "\t\ttest_per=0.230, time=9s\n",
      "Epoch 6/100:, \n",
      "train_loss=32.866, time = 84s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/finetunning/ckpt-6\n",
      "\tdev_loss=32.380, time = 4s\n",
      "INFO:tensorflow:Restoring parameters from ./model/cnn+ctc/finetunning/ckpt-6\n",
      "\t\ttest_per=0.231, time=9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-46d71ce04bc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             _, cost = ft_train_sess.run([ft_train_model.update_step, ft_train_model.loss], feed_dict={ft_train_model.keep_prob: 0.7,\n\u001b[1;32m---> 32\u001b[1;33m                                                                                                      ft_train_model.training: True})\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mft_train_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sappyprg\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sappyprg\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sappyprg\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sappyprg\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sappyprg\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ft_train_graph = tf.Graph()\n",
    "ft_dev_graph = tf.Graph()\n",
    "ft_test_graph = tf.Graph()\n",
    "\n",
    "with ft_train_graph.as_default():\n",
    "    ft_train_model = Model(ft_batch_size, num_hidden, n_hidden_layer, feats_dim, num_classes, ft_learning_rate, optimizer='momentum',\n",
    "                        file_type=TRAIN_FILE, model_type='train')\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    \n",
    "with ft_dev_graph.as_default():\n",
    "    ft_dev_model = Model(ft_batch_size, num_hidden, n_hidden_layer, feats_dim, num_classes, file_type=DEV_FILE, model_type='eval')\n",
    "\n",
    "with ft_test_graph.as_default():\n",
    "    ft_test_model = Model(ft_batch_size, num_hidden, n_hidden_layer, feats_dim, num_classes, \n",
    "                       phn_61=phn_61, phn_39=phn_39, mapping=mapping, file_type=TEST_FILE, model_type='infer')\n",
    "\n",
    "ft_train_sess = tf.Session(graph=ft_train_graph)\n",
    "ft_train_sess.run(initializer)\n",
    "ft_dev_sess = tf.Session(graph=ft_dev_graph)\n",
    "ft_test_sess = tf.Session(graph=ft_test_graph)\n",
    "ft_test_sess.run(ft_test_model.mapping_table_init)\n",
    "\n",
    "ft_train_model.saver.restore(ft_train_sess, restored_ckpt_path)\n",
    "\n",
    "for epoch in range(ft_epochs):\n",
    "    ft_train_sess.run(ft_train_model.iterator_initializer)\n",
    "    ft_train_loss  = []\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            _, cost = ft_train_sess.run([ft_train_model.update_step, ft_train_model.loss], feed_dict={ft_train_model.keep_prob: 0.7,\n",
    "                                                                                                     ft_train_model.training: True})\n",
    "            ft_train_loss.append(cost)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            end = time.time()\n",
    "            log = \"Epoch {}/{}:, \\ntrain_loss={:.3f}, time = {:.0f}s\"\n",
    "            print(log.format(epoch+1, ft_epochs, np.mean(ft_train_loss), end-start))\n",
    "            ft_checkpoint_path = ft_train_model.saver.save(ft_train_sess, ft_checkpoints_path, global_step=epoch+1)\n",
    "            \n",
    "            ft_dev_model.saver.restore(ft_dev_sess, ft_checkpoint_path)\n",
    "            ft_dev_sess.run(ft_dev_model.iterator_initializer)\n",
    "            ft_dev_loss = []\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                try:\n",
    "                    cost = ft_dev_sess.run(ft_dev_model.loss, feed_dict={ft_dev_model.keep_prob: 1.0, ft_dev_model.training: False})\n",
    "                    ft_dev_loss.append(cost)\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    end = time.time()\n",
    "                    log = \"\\tdev_loss={:.3f}, time = {:.0f}s\"\n",
    "                    print(log.format(np.mean(ft_dev_loss), end-start))\n",
    "                    break\n",
    "                \n",
    "            ft_test_model.saver.restore(ft_test_sess, ft_checkpoint_path)\n",
    "            ft_test_sess.run(ft_test_model.iterator_initializer)\n",
    "            ft_test_per = []\n",
    "            ft_test_seq_len = []\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                try:\n",
    "                    _per, seq_len = ft_test_sess.run(ft_test_model.per, feed_dict={ft_test_model.keep_prob: 1.0, ft_test_model.training: False})\n",
    "                    ft_test_per.append(_per)\n",
    "                    ft_test_seq_len.append(seq_len)\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    end = time.time()\n",
    "                    log = '\\t\\ttest_per={:.3f}, time={:.0f}s'\n",
    "                    print(log.format(sum(ft_test_per)/sum(ft_test_seq_len), end-start))\n",
    "                    break\n",
    "            # go to netxt epoch\n",
    "            break\n",
    "        \n",
    "        \n",
    "ft_train_sess.close()\n",
    "ft_dev_sess.close()\n",
    "ft_test_sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
