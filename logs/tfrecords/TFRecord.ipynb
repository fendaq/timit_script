{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from python_speech_features import mfcc, fbank, delta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.io.wavfile as wav\n",
    "import subprocess\n",
    "import os, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## original phonemes\n",
    "phn_61 = ['aa', 'ae', 'ah', 'ao', 'aw', 'ax', 'ax-h', 'axr', 'ay', 'b', 'bcl', 'ch', 'd', 'dcl', 'dh', 'dx', 'eh', 'el', 'em', 'en', 'eng', 'epi', 'er', 'ey', 'f', 'g', 'gcl', 'h#', 'hh', 'hv', 'ih', 'ix', 'iy', 'jh', 'k', 'kcl', 'l', 'm', 'n', 'ng', 'nx', 'ow', 'oy', 'p', 'pau', 'pcl', 'q', 'r', 's', 'sh', 't', 'tcl', 'th', 'uh', 'uw', 'ux', 'v', 'w', 'y', 'z', 'zh']\n",
    "\n",
    "mapping = {'ah': 'ax', 'ax-h': 'ax', 'ux': 'uw', 'aa': 'ao', 'ih': 'ix', \\\n",
    "               'axr': 'er', 'el': 'l', 'em': 'm', 'en': 'n', 'nx': 'n',\\\n",
    "               'eng': 'ng', 'sh': 'zh', 'hv': 'hh', 'bcl': 'h#', 'pcl': 'h#',\\\n",
    "               'dcl': 'h#', 'tcl': 'h#', 'gcl': 'h#', 'kcl': 'h#',\\\n",
    "               'q': 'h#', 'epi': 'h#', 'pau': 'h#'}\n",
    "\n",
    "phn_39 = ['ae', 'ao', 'aw', 'ax', 'ay', 'b', 'ch', 'd', 'dh', 'dx', 'eh', \\\n",
    "             'er', 'ey', 'f', 'g', 'h#', 'hh', 'ix', 'iy', 'jh', 'k', 'l', \\\n",
    "             'm', 'n', 'ng', 'ow', 'oy', 'p', 'r', 's', 't', 'th', 'uh', 'uw',\\\n",
    "             'v', 'w', 'y', 'z', 'zh']\n",
    "\n",
    "TIMIT_DIR = './timit'\n",
    "DATA_DIR = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_tfrecords_from_timit(feat_type='mfcc'):\n",
    "        \n",
    "    if not os.path.isdir(DATA_DIR):\n",
    "        os.makedirs(DATA_DIR)\n",
    "    \n",
    "    for data_type in ['train', 'test']:\n",
    "        timit_dir = os.path.join(TIMIT_DIR, data_type)\n",
    "        writer = tf.python_io.TFRecordWriter(os.path.join(DATA_DIR, (data_type + '.tfrecords')))\n",
    "        feats_list = []\n",
    "        phoneme_list = []\n",
    "        start = time.time()\n",
    "        cnt = 0\n",
    "        for path, dirs, files in os.walk(timit_dir):\n",
    "            for file in files:\n",
    "                if file.startswith('sa'): # exclude all 'SA' files according to 'https://github.com/zzw922cn/Automatic_Speech_Recognition'\n",
    "                    continue\n",
    "                if file.endswith('wav'):\n",
    "                    # .wav\n",
    "                    fullFileName = os.path.join(path, file)\n",
    "                    fnameNoSuffix = os.path.splitext(fullFileName)[0]\n",
    "                    fNameTmp = fnameNoSuffix + '_tmp.wav'\n",
    "                    subprocess.call(['sox', fullFileName, fNameTmp], shell=True)\n",
    "                    rate, sig = wav.read(fNameTmp)\n",
    "                    os.remove(fNameTmp)\n",
    "\n",
    "                    if feat_type == 'mfcc':\n",
    "                        mfcc_feat = mfcc(sig, rate)\n",
    "                        mfcc_feat_delta = delta(mfcc_feat, 2)\n",
    "                        mfcc_feat_delta_delta = delta(mfcc_feat_delta, 2)\n",
    "                        feats = np.concatenate((mfcc_feat, mfcc_feat_delta, mfcc_feat_delta_delta), axis=-1)\n",
    "                    else: # log Mel-filterbank energy + total energy\n",
    "                        filters, energy = fbank(sig, rate, nfilt=40)\n",
    "                        log_filters = np.log(filters)\n",
    "                        logfbank_feat = np.concatenate((log_filters, energy.reshape(-1,1)), axis=-1)\n",
    "                        logfbank_feat_delta = delta(logfbank_feat, 2)\n",
    "                        logfbank_feat_delta_delta = delta(logfbank_feat_delta, 2)\n",
    "                        feats = np.concatenate((logfbank_feat, logfbank_feat_delta, logfbank_feat_delta_delta), axis=-1)\n",
    "                    feats_list.append(feats)\n",
    "\n",
    "                    # .phn\n",
    "                    phoneme = []\n",
    "                    with open(fnameNoSuffix + '.phn', 'r') as f:\n",
    "                        for line in f.read().splitlines():\n",
    "                            phn = line.split(' ')[2]\n",
    "                            p_index = phn_61.index(phn)\n",
    "                            phoneme.append(p_index)\n",
    "                    phoneme_list.append(phoneme)\n",
    "\n",
    "                    cnt += 1\n",
    "        if data_type == 'train':\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(np.concatenate(feats_list, axis=0))\n",
    "        for feats, phoneme in zip(feats_list, phoneme_list):\n",
    "            seq_exam = tf.train.SequenceExample()\n",
    "            seq_exam.context.feature['feats_dim'].int64_list.value.append(feats.shape[1])\n",
    "            seq_exam.context.feature['feats_seq_len'].int64_list.value.append(feats.shape[0])\n",
    "            seq_exam.context.feature['labels_seq_len'].int64_list.value.append(len(phoneme))\n",
    "\n",
    "            scaler.transform(feats)\n",
    "            for feat in feats:\n",
    "                seq_exam.feature_lists.feature_list['features'].feature.add().float_list.value[:] = feat\n",
    "            for p in phoneme:\n",
    "                seq_exam.feature_lists.feature_list['labels'].feature.add().int64_list.value.append(p)\n",
    "            writer.write(seq_exam.SerializeToString())\n",
    "                    \n",
    "        writer.close()\n",
    "        print('{}-{}: {} utterances - {:.0f}s'.format(data_type, feat_type, cnt, (time.time()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_tfrecords_from_timit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer([os.path.join(DATA_DIR, 'test.tfrecords')], num_epochs=1)\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "context_features = {'feats_dim': tf.FixedLenFeature([], dtype=tf.int64), \n",
    "                    'feats_seq_len': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "                    'labels_seq_len': tf.FixedLenFeature([], dtype=tf.int64)}\n",
    "sequence_features = {'features': tf.FixedLenSequenceFeature([39], dtype=tf.float32),\n",
    "                     'labels': tf.FixedLenSequenceFeature([], dtype=tf.int64)}\n",
    "context_parsed, sequence_parsed = tf.parse_single_sequence_example(serialized_example,\n",
    "                                                                  context_features=context_features,\n",
    "                                                                  sequence_features=sequence_features)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    try:\n",
    "        step = 0\n",
    "        while not coord.should_stop():\n",
    "            print('step: {}'.format(step))\n",
    "            feats_dim, feats_seq_len, labels_seq_len, features, labels = sess.run([context_parsed['feats_dim'], \n",
    "                                                                context_parsed['feats_seq_len'], context_parsed['labels_seq_len'],\n",
    "                                                                sequence_parsed['features'], sequence_parsed['labels']])\n",
    "            print(feats_seq_len)\n",
    "            print(labels_seq_len)\n",
    "            print()\n",
    "            step += 1\n",
    "            \n",
    "            if step >= 1:\n",
    "                break\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        \n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_dim, features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.contrib.data.TFRecordDataset(os.path.join(DATA_DIR, 'test.tfrecords'))\n",
    "context_features = {'feats_dim': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "                    'feats_seq_len': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "                    'labels_seq_len': tf.FixedLenFeature([], dtype=tf.int64)}\n",
    "sequence_features = {'features': tf.FixedLenSequenceFeature([39], dtype=tf.float32),\n",
    "                     'labels': tf.FixedLenSequenceFeature([], dtype=tf.int64)}\n",
    "test_dataset = test_dataset.map(lambda serialized_example : tf.parse_single_sequence_example(serialized_example, \n",
    "                                                                  context_features=context_features,\n",
    "                                                                  sequence_features=sequence_features))\n",
    "test_dataset = test_dataset.map(lambda context, sequence: (context['feats_dim'], context['feats_seq_len'],\n",
    "                                                        context['labels_seq_len'], sequence['features'], sequence['labels']))\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "feats_dim, feats_seq_len, labels_seq_len, features, labels = test_iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(test_iterator.initializer)\n",
    "    \n",
    "    while True:\n",
    "        step = 0\n",
    "        try:\n",
    "            r = sess.run([feats_dim, feats_seq_len, labels_seq_len, features, labels])\n",
    "            step += 1\n",
    "            \n",
    "            if step >= 1:\n",
    "                break\n",
    "        except tf.errors.OutOfRangeError:\n",
    "                print('finish epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0], r[1], r[2], r[3].shape, r[4].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
