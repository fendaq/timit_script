{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sox: convert timit file format to .wav\n",
    "* sklearn: framewise zero mean, unit variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'SA' files removed\n",
    "* reduced phoneme 61 -> 39\n",
    "* 3696 train, 1344 test total 5040 utterances\n",
    "* speech features: mfcc [num of cepstrum: 13, windows length: 25ms, windows distance: 10ms] + delta + delta_delta -> total 39 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from python_speech_features import mfcc, delta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.io.wavfile as wav\n",
    "import subprocess\n",
    "import os, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## original phonemes\n",
    "phn_61 = ['aa', 'ae', 'ah', 'ao', 'aw', 'ax', 'ax-h', 'axr', 'ay', 'b', 'bcl', 'ch', 'd', 'dcl', 'dh', 'dx', 'eh', 'el', 'em', 'en', 'eng', 'epi', 'er', 'ey', 'f', 'g', 'gcl', 'h#', 'hh', 'hv', 'ih', 'ix', 'iy', 'jh', 'k', 'kcl', 'l', 'm', 'n', 'ng', 'nx', 'ow', 'oy', 'p', 'pau', 'pcl', 'q', 'r', 's', 'sh', 't', 'tcl', 'th', 'uh', 'uw', 'ux', 'v', 'w', 'y', 'z', 'zh']\n",
    "\n",
    "mapping = {'ah': 'ax', 'ax-h': 'ax', 'ux': 'uw', 'aa': 'ao', 'ih': 'ix', \\\n",
    "               'axr': 'er', 'el': 'l', 'em': 'm', 'en': 'n', 'nx': 'n',\\\n",
    "               'eng': 'ng', 'sh': 'zh', 'hv': 'hh', 'bcl': 'h#', 'pcl': 'h#',\\\n",
    "               'dcl': 'h#', 'tcl': 'h#', 'gcl': 'h#', 'kcl': 'h#',\\\n",
    "               'q': 'h#', 'epi': 'h#', 'pau': 'h#'}\n",
    "\n",
    "phn_39 = ['ae', 'ao', 'aw', 'ax', 'ay', 'b', 'ch', 'd', 'dh', 'dx', 'eh', \\\n",
    "             'er', 'ey', 'f', 'g', 'h#', 'hh', 'ix', 'iy', 'jh', 'k', 'l', \\\n",
    "             'm', 'n', 'ng', 'ow', 'oy', 'p', 'r', 's', 't', 'th', 'uh', 'uw',\\\n",
    "             'v', 'w', 'y', 'z', 'zh']\n",
    "\n",
    "TRAIN_DIR_TIMIT = os.path.join('timit','train')\n",
    "TRAIN_DIR_FEATS = os.path.join('data','train','feats')\n",
    "TRAIN_DIR_LABELS = os.path.join('data','train','labels')\n",
    "\n",
    "TEST_DIR_TIMIT = os.path.join('timit','test')\n",
    "TEST_DIR_FEATS = os.path.join('data','test','feats')\n",
    "TEST_DIR_LABELS = os.path.join('data','test','labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_feats_labels_files(types='train', reduced_phn=True):\n",
    "    \n",
    "    if types == 'train':\n",
    "        DIR = (TRAIN_DIR_TIMIT, TRAIN_DIR_FEATS, TRAIN_DIR_LABELS)\n",
    "    else: # types == 'test'\n",
    "        DIR = (TEST_DIR_TIMIT, TEST_DIR_FEATS, TEST_DIR_LABELS)\n",
    "        \n",
    "    if not os.path.isdir(DIR[1]):\n",
    "        os.makedirs(DIR[1])\n",
    "    if not os.path.isdir(DIR[2]):\n",
    "        os.makedirs(DIR[2])\n",
    "    \n",
    "    start = time.time()\n",
    "    cnt = 0\n",
    "    for path, dirs, files in os.walk(DIR[0]):\n",
    "        for file in files:\n",
    "            if file.startswith('sa'): # remove all 'SA' files according to 'https://github.com/zzw922cn/Automatic_Speech_Recognition'\n",
    "                continue\n",
    "            if file.endswith('wav'):\n",
    "                # .wav\n",
    "                fullFileName = os.path.join(path, file)\n",
    "                fnameNoSuffix = os.path.splitext(fullFileName)[0]\n",
    "                fNameTmp = fnameNoSuffix + '_tmp.wav'\n",
    "                subprocess.call(['sox', fullFileName, fNameTmp], shell=True)\n",
    "                rate, sig = wav.read(fNameTmp)\n",
    "                \n",
    "                mfcc_feat = mfcc(sig, rate)\n",
    "                mfcc_feat_delta = delta(mfcc_feat, 2)\n",
    "                mfcc_feat_delta_delta = delta(mfcc_feat_delta, 2)\n",
    "                mfcc_feat_concat = np.concatenate((mfcc_feat, mfcc_feat_delta, mfcc_feat_delta_delta), axis=1)\n",
    "                \n",
    "                featFileName = os.path.join(DIR[1], fnameNoSuffix.split(os.sep)[-2] + '-' + fnameNoSuffix.split(os.sep)[-1] + '.npy')\n",
    "                np.save(featFileName, mfcc_feat_concat)\n",
    "                os.remove(fNameTmp)\n",
    "                \n",
    "                # .phn\n",
    "                phoneme = []\n",
    "                with open(fnameNoSuffix + '.phn', 'r') as f:\n",
    "                    for line in f.read().splitlines():\n",
    "                        phn = line.split(' ')[2]\n",
    "                        if reduced_phn:\n",
    "                            if phn in mapping.keys():\n",
    "                                p_index = phn_39.index(mapping[phn])\n",
    "                            else:\n",
    "                                p_index = phn_39.index(phn)\n",
    "                        else:\n",
    "                            p_index = phn_61.index(phn)\n",
    "                        phoneme.append(p_index)\n",
    "                phoneme = np.array(phoneme)\n",
    "                \n",
    "                labelFileName = os.path.join(DIR[2], fnameNoSuffix.split(os.sep)[-2] + '-' + fnameNoSuffix.split(os.sep)[-1] + '.npy')\n",
    "                np.save(labelFileName, phoneme)\n",
    "                \n",
    "                cnt += 1\n",
    "    print('{}: {} utterances - {:.0f}s'.format(types, cnt, (time.time()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 1344 utterances - 74s\n"
     ]
    }
   ],
   "source": [
    "gen_feats_labels_files(types='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3696 utterances - 208s\n"
     ]
    }
   ],
   "source": [
    "gen_feats_labels_files(types='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_features():\n",
    "    start = time.time()\n",
    "    X_train = []\n",
    "    for file in os.listdir(TRAIN_DIR_FEATS):\n",
    "        X_train.append(np.load(os.path.join(TRAIN_DIR_FEATS, file)))\n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    for file in os.listdir(TRAIN_DIR_FEATS):\n",
    "        fname = os.path.join(TRAIN_DIR_FEATS, file)\n",
    "        X = np.load(fname)\n",
    "        scaler.transform(X)\n",
    "        np.save(fname, X)\n",
    "    \n",
    "    for file in os.listdir(TEST_DIR_FEATS):\n",
    "        fname = os.path.join(TEST_DIR_FEATS, file)\n",
    "        X = np.load(fname)\n",
    "        scaler.transform(X)\n",
    "        np.save(fname, X)\n",
    "    \n",
    "    print('{:.0f}s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale_features()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
